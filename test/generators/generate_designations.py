"""
Generate dummy data for the Designation table.

Note: designationid is SERIAL (auto-generated by database), so it will be
ignored during upload. The database will assign IDs automatically.
"""
from __future__ import annotations

import argparse
import os
import sys
from pathlib import Path

try:
    import psycopg2
    import psycopg2.extras
    from dotenv import load_dotenv
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False

from _shared import generate_designations
from utils import ensure_parent_dir, save_and_report


def get_max_designation_id_from_db() -> int:
    """Get the maximum designation ID from the database to avoid conflicts."""
    if not DB_AVAILABLE:
        return 0
    
    # Load environment variables - try multiple locations
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    backend_dir = project_root / 'Backend'
    
    env_loaded = False
    for env_path in [
        script_dir / '.env',
        backend_dir / '.env',
        project_root / '.env',
    ]:
        if env_path.exists():
            load_dotenv(env_path)
            env_loaded = True
            break
    
    if not env_loaded:
        load_dotenv()
    
    database_url = os.environ.get('DATABASE_URL')
    
    if not database_url:
        return 0
    
    conn = None
    try:
        conn = psycopg2.connect(database_url)
        cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        
        cur.execute("SELECT MAX(designationid) as max_id FROM designation;")
        row = cur.fetchone()
        max_id = row['max_id'] if row and row['max_id'] else 0
        
        return max_id
    except Exception as e:
        print(f"Warning: Could not fetch max designation ID from database: {e}", file=sys.stderr)
        return 0
    finally:
        if conn:
            cur.close()
            conn.close()


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Generate dummy Designation data. "
        "Note: designationid is SERIAL and will be auto-generated by the database."
    )
    parser.add_argument(
        "--count",
        type=int,
        default=10,
        help="Number of designation records to generate (default: 10).",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("designation.csv"),
        help="Output CSV path (default: designation.csv).",
    )
    parser.add_argument(
        "--check-db",
        action="store_true",
        help="Check database for existing max ID to avoid conflicts (default: auto-detect).",
    )
    parser.add_argument(
        "--no-db-check",
        action="store_true",
        help="Disable database check for existing IDs.",
    )
    return parser


def main():
    parser = build_parser()
    args = parser.parse_args()

    # Check database for existing IDs if enabled
    max_id = 0
    if (args.check_db or (not args.no_db_check and DB_AVAILABLE)):
        max_id = get_max_designation_id_from_db()
        if max_id > 0:
            print(
                f"ℹ Found existing designations up to ID {max_id} in database. "
                "Note: designationid is SERIAL and will be auto-generated during upload.",
                file=sys.stderr
            )

    output_path = ensure_parent_dir(Path(args.output))
    with output_path.open("w", encoding="utf-8") as outfile:
        generate_designations(outfile, args.count)

    save_and_report(output_path, "✓ Generated Designation data")
    print(
        "Note: The designationid column in the CSV will be ignored during upload "
        "since it's a SERIAL (auto-generated) column.",
        file=sys.stderr
    )


if __name__ == "__main__":
    main()

